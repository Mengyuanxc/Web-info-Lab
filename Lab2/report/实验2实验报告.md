<center><h2> 实验2实验报告</h2></center>
<center><font size = 1> PB21000057 顾荣健 &emsp; PB21000069 林润锋(组长) &emsp; PB21000074 田钦 </font></center>

### 第一阶段.图谱抽取
#### 1.0 实验要求:
从公开图谱中匹配指定电影对应的实体，并抽取合适的部分图谱，按照规则对抽取到的图谱进行处理

#### 1.1 实验过程

##### 1.1.1 匹配实体

根据实验一中提供的电影ID列表，在freebase中匹配对应的实体

在链接信息文件`douban2fb.txt`中，可以得到豆瓣电影ID与freebase图谱实体ID之间的映射关系，以每行两列，第一列为豆瓣电影ID，第二列为freebase图谱实体ID的形式给出，由此文件构造映射关系后，再读取实验一中给出的电影ID，据此在映射表中找到对应的实体ID，核心代码如下

###### 映射的构建

```py
convert_dict = {}
with open("data/douban2fb.txt", "r") as convert_txt:
    for line in convert_txt:
        line = line.strip()
        # print(line)
        convert_list = line.split("\t")
        convert_dict[convert_list[0]] = convert_list[1]
```

###### 对应实体查找

```py
# movie_dict 为电影id到mid的映射
# movie_dict_reverse 为mid到电影id的映射
movie_dict = {}
movie_dict_reverse = {}
with open("data/Movie_id.csv", "r") as movie_id_csv:
    csv_reader = csv.reader(movie_id_csv)
    for row in csv_reader:
        # print(row)
        if row[0] in convert_dict:
            movie_dict[row[0]] = convert_dict[row[0]]
            movie_dict_reverse[convert_dict[row[0]]] = row[0]
```

##### 1.1.2 三元组的构建与存储

根据1.1.1中匹配出的实体，查找一跳可以形成关联的三元组并进行存储

核心代码如下

```py
with gzip.open('data/freebase_douban.gz', 'rb') as f:
    for line_num, line in tqdm(enumerate(f, start=1), total=line_count):
        line = line.strip()
        triplet = line.decode().split('\t')[:3]
        mid = triplet[0].split('/')[-1][:-1]
        if mid in movie_dict_reverse:
            if triplet[1].startswith("<http://rdf.freebase.com/ns"):
                movie_triplet_dict.setdefault(mid, [])
                movie_triplet_dict[mid].append(triplet)
```

为了保证图谱的质量，我们对图谱进行过滤，采用采样核=20、关系数阈值=50进行过滤，也即只保留三元组至少有20个的实体、至少出现50次的实体，关键代码如下

```py
for movie in original_dict:
    all_triplet = original_dict[movie]
    for triplet in all_triplet:
        relationship = triplet[1]
        child_entity = triplet[2]  # 尾entity
        relationship_count_map.setdefault(relationship, 0)
        relationship_count_map[relationship] += 1
        if relationship_count_map[relationship] > relationship_threshold:
            available_relationship.add(relationship)
        child_count_map.setdefault(child_entity, 0)
        child_count_map[child_entity] += 1
        if child_count_map[child_entity] >= entity_core:
            available_child_entity.add(child_entity)
```

通过这一过程可以对三元组进行过滤，从而保证了图谱的质量

此外，对于原本处理好的三元组再次进行处理（即重复一次三元组的构建），得到两跳后形成的子图以保证图谱的关联性


### 第二阶段.图谱推荐
#### 2.0 实验要求：
基于对实验一中的豆瓣电影评分数据，结合本实验阶段一中所获得的图谱信息，进行可解释的、知识感知的个性化电影推荐
#### 2.1实验过程

##### 2.1.1 构建映射关系

###### ① 将电影实体映射到`[0, num of movies)`范围内

从阶段一中获取实体id和豆瓣电影id的映射关系，从`movie_id.csv`文件中获取豆瓣电影id到`[0, num of movies)`的映射关系，再将两个映射关系结合，就能完成将电影实体id到`[0, num of movies)`范围的映射

实现的核心代码如下

```py
midToIdmap = {} # mid->id
with open("data/douban2fb.txt", "r") as f:
    for line in f:
        line = line.strip()
        # print(line)
        convert_list = line.split("\t")
        midToIdmap[convert_list[1]] = convert_list[0]
Idmap = {}  # id->0——movie_num
with open("data/movie_id_map.txt", "r") as f:
    for line in f:
        line = line.strip()
        # print(line)
        convert_list = line.split("\t")
        Idmap[convert_list[0]] = convert_list[1]
for key in midToIdmap:
    midToIdmap[key] = Idmap[midToIdmap[key]]
```

###### ②将图谱中的其他实体映射到`[num of movies, num of entities)`范围内，将关系映射到`[0, num of relations)`范围内

对于每一个图谱中的三元组，将其中的头、尾实体（除去在①中已经进行了映射的实体）和关系分别进行映射

实现的核心代码如下

```py
for movie in movie_triplet_dict:
    # 头的映射
    cnt += 1
    triplet = []
    movie_str = movie[0][28:-1]
    if movie_str in midToIdmap:  # 构造映射
        movie_id = midToIdmap[movie_str]
        triplet.append(int(movie_id))
        movie_cnt += 1
    else:
        if movie[0] in non_movie_map:  # 在表中了
            triplet.append(non_movie_map[movie[0]])
        else:  # 不在映射表里
            non_movie_map[movie[0]] = non_movie_cnt
            triplet.append(non_movie_cnt)
            non_movie_cnt += 1

    # 关系的映射
    if movie[1] in relationship_map:  # 在表中了
        triplet.append(relationship_map[movie[1]])
    else:  # 不在映射表里
        relationship_map[movie[1]] = relationship_cnt
        triplet.append(relationship_cnt)
        relationship_cnt += 1

    # 尾的映射
    movie_str = movie[2][28:-1]
    if movie_str in midToIdmap:  # 构造映射
        movie_id = midToIdmap[movie_str]
        triplet.append(int(movie_id))
        movie_cnt += 1
    else:
        if movie[2] in non_movie_map:  # 在表中了
            triplet.append(non_movie_map[movie[2]])
        else:  # 不在映射表里
            non_movie_map[movie[2]] = non_movie_cnt
            triplet.append(non_movie_cnt)
            non_movie_cnt += 1
    triplets_columns.append(triplet)
```

##### 2.1.2 基于 baseline 框架代码，完成基于图谱嵌入的模型

###### ① `loader_Embedding_based.py`实现KG的构建

对于函数声明：

```py
class DataLoader(DataLoaderBase):
    
    def construct_data(self, kg_data):
```

在其中实现如下功能

1. 为KG添加逆向三元组，即对于KG中任意三元组`(h, r, t)`，添加逆向三元组 `(t, r+n_relations, h)`，并将原三元组和逆向三元组拼接为新的`DataFrame`，保存在 `self.kg_data` 中


2. 计算关系数，实体数和三元组的数量

3. 根据`self.kg_data`构建字典`self.kg_dict`，其中`key`为`h`, `value`为`tuple(t, r)`，和字典 `self.relation_dict`，其中`key`为`r`, `value`为`tuple(h, t)`。

核心代码如下

```py
def construct_data(self, kg_data):
        self.n_relations = 0  # 计算关系数
        self.n_entities = 0  # 计算实体数
        data = {}
        data['h'] = []
        data['r'] = []
        data['t'] = []
        for i in range(0, kg_data.shape[0]):
            """
            循环计算关系数和实体数
            """
            if (kg_data.loc[i]["r"] > self.n_relations):
                self.n_relations = kg_data.loc[i]["r"]
            if (kg_data.loc[i]["h"] > self.n_entities):
                self.n_entities = kg_data.loc[i]["h"]
            if (kg_data.loc[i]["t"] > self.n_entities):
                self.n_entities = kg_data.loc[i]["t"]
        self.n_relations += 1
        self.n_entities += 1

        ori_len = kg_data.shape[0]  # 记录原来的长度
        # 获取反转并生成字典
        self.kg_dict = collections.defaultdict(list)
        self.relation_dict = collections.defaultdict(list)
        for i in range(0, ori_len):
            rows = kg_data.loc[i]
            data['h'].append(rows['t'])
            data['t'].append(rows['h'])
            data['r'].append(rows['r'] + self.n_relations)
            self.kg_dict[rows['h']].append((rows['t'], rows['r']))
            self.kg_dict[rows['t']].append((rows['h'], rows['r'] + self.n_relations))
            self.relation_dict[rows['r']].append((rows['h'], rows['t']))
            self.relation_dict[rows['r'] + self.n_relations].append((rows['t'], rows['h']))
        self.kg_data = pd.concat([kg_data, pd.DataFrame(data)], ignore_index=True)
        self.n_relations *= 2  # 翻倍了
        self.n_kg_data = self.kg_data.shape[0]
        print(
            "数据处理完毕,关系数为:" + str(self.n_relations) + "实体数为:" + str(self.n_entities) + "三元组数为:" + str(
                self.n_kg_data))
```

###### ② `Embedding_based.py`实现TransE算法

对于函数声明：

```py
class Embedding_based(nn.Module):
    
    def calc_kg_loss_TransR(self, h, r, pos_t, neg_t):
```

在其中实现如下功能

1. 计算头实体，尾实体和负采样的尾实体在对应关系空间中的投影嵌入

   使用库`PyTorch`中的函数`torch.einsum`实现爱因斯坦求和约定（Einstein summation notation）运算，来计算头实体，尾实体和负采样的尾实体在对应关系空间中的投影嵌入，代码如下

   ```py
   r_mul_h = torch.einsum('abc,ac->ab', [W_r, h_embed])  # (kg_batch_size, relation_dim)
   r_mul_pos_t = torch.einsum('abc,ac->ab', [W_r, pos_t_embed])  # (kg_batch_size, relation_dim)
   r_mul_neg_t = torch.einsum('abc,ac->ab', [W_r, neg_t_embed])  # (kg_batch_size, relation_dim)
   ```

2. 对关系嵌入，头实体嵌入，尾实体嵌入，负采样的尾实体嵌入进行L2范数归一化

   对于一维向量$\bold{x}=(x_1,x_2,...,x_n)$，其L2范数归一化的结果为$\bold{x'}=(\frac{x_1}{|\bold{x}|},\frac{x_2}{|\bold{x}|},...,\frac{x_n}{|\bold{x}|})$

   可以采用库`PyTorch`中的函数`F.normalize(x,p,dim)`进行向量的归一化，其中x是向量名，p代表范数的计算方式，这里取`p=2`即在欧式几何下取$|\bold{x}|=\sqrt{x_1^2+x_2^2+...+x_n^2}$作为其范数，dim是维度，代码实现如下

   ```py
   r_embed = F.normalize(r_embed, p=2, dim=1)
   r_mul_h = F.normalize(r_mul_h, p=2, dim=1)
   r_mul_pos_t = F.normalize(r_mul_pos_t, p=2, dim=1)
   r_mul_neg_t = F.normalize(r_mul_neg_t, p=2, dim=1)
   ```

3. 分别计算正样本三元组`(h_embed, r_embed, pos_t_embed)` 和负样本三元组`(h_embed, r_embed, neg_t_embed)` 的得分

   将三元组对应的向量列分别相乘再求和，就得到了样本三元组的得分，使用库`PyTorch`中的函数`torch.sum`进行实现，代码如下

   ```py
   pos_score = torch.sum(r_mul_h * r_embed * pos_t_embed, dim=1)  # (kg_batch_size)
   neg_score = torch.sum(r_mul_h * r_embed * neg_t_embed, dim=1)  # (kg_batch_size)
   ```

4. 使用 BPR Loss 进行优化，尽可能使负样本的得分大于正样本的得分

   ```py
   kg_loss = -torch.mean(torch.log(torch.sigmoid(pos_score - neg_score)))
   ```

对于函数声明：

```py
class Embedding_based(nn.Module):
    
	def calc_kg_loss_TransE(self, h, r, pos_t, neg_t):
```

在其中实现以下功能

5. 对关系嵌入，头实体嵌入，尾实体嵌入，负采样的尾实体嵌入进行L2范数归一化
6. 分别计算正样本三元组`(h_embed, r_embed, pos_t_embed)`和负样本三元组`(h_embed, r_embed, neg_t_embed)`的得分
7. 使用 BPR Loss 进行优化，尽可能使负样本的得分大于正样本的得分

对于函数声明：

```py
class Embedding_based(nn.Module):
    
	def calc_cf_loss(self, user_ids, item_pos_ids, item_neg_ids):
```

在其中实现如下内容

8. 为物品嵌入注入实体嵌入的语义信息

   ```py
   item_pos_cf_embed = item_pos_embed + item_pos_kg_embed  # (cf_batch_size, embed_dim)
   item_neg_cf_embed = item_neg_embed + item_neg_kg_embed  # (cf_batch_size, embed_dim)
   ```

对于函数声明：

```py
class Embedding_based(nn.Module):
    
	def calc_score(self, user_ids, item_ids):
```

在其中实现如下内容

9. 为物品嵌入注入实体嵌入的语义信息

   ```py
   item_cf_embed = item_embed + item_kg_embed  # (n_items, embed_dim)
   ```

###### ③ 采用多任务方式进行模型更新

多任务方式即是将KG损失和CF损失相加。

在给出的代码框架中，已经包含了两个损失相加部分的代码，如下所示：

   ```python
   kg_loss = calc_kg_loss(h, r, pos_t, neg_t)
   cf_loss = self.calc_cf_loss(user_ids, item_pos_ids, item_neg_ids)
   
   loss = kg_loss + cf_loss
   ```

通过这个加和后的loss更新模型，就可以考虑KG和CF的共同影响。

#### 2.2 实验结果

运行main程序，得到如下结果：

1. 对于不包含知识图谱的神经网络：

   ```
   Best CF Evaluation: Epoch 0040 | Precision [0.2975, 0.2579], Recall [0.0669, 0.1130], NDCG [0.3054, 0.2821]
   Recall@5: 0.0669
   Recall@10: 0.1130
   NDCG@5: 0.3054
   NDCG@10: 0.2821
   ```

   可以得到一个基准的测试结果。

   > 从绝对数值而言，这个基准测试结果并不好。上述值均比较低，说明推荐效果很一般。但是通过后续实验发现，这个值的绝对大小和选择的模型关系不大。
   >
   > 分析原因，可能出自选择的数据集。我们选择的数据集包含了10万多的三元组；如果能够增加三元组数目，或许能够提高准确率。

2. 对于embedding based method：

   * TransE算法：

     ```
     Best CF Evaluation: Epoch 0050 | Precision [0.2940, 0.2539], Recall [0.0656, 0.1094], NDCG [0.3000, 0.2770]
     Recall@5: 0.0656
     Recall@10: 0.1094
     NDCG@5: 0.3000
     NDCG@10: 0.2770
     ```
   
   * TransR算法：
   
     ```
     Best CF Evaluation: Epoch 0060 | Precision [0.2787, 0.2400], Recall [0.0621, 0.1012], NDCG [0.2833, 0.2609]
     Recall@5: 0.0621
     Recall@10: 0.1012
     NDCG@5: 0.2833
     NDCG@10: 0.2609
     ```

### 3 实验总结

在本次实验中，我们从公开图谱中匹配指定电影对应的实体，并抽取合适的部分图谱，按照规则对抽取到的图谱进行处理（Stage1）；进而，我们基于对实验一中的豆瓣电影评分数据，并结合 Stage1 所获得的图谱信息，实现了可解释的、知识感知的个性化电影推荐（Stage2）。

